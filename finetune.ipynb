{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data_reading import CompressedWindowDataset, CocoWindowDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tools import utils\n",
    "from tools.engine import train_one_epoch, evaluate\n",
    "from model_zoo.InputInjection import InputInjection\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = CocoWindowDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229 2197\n"
     ]
    }
   ],
   "source": [
    "noneC = 0\n",
    "for i in range(len(dataset)):\n",
    "    img, spectr, lab = dataset[i]\n",
    "    if img is None:\n",
    "        noneC += 1\n",
    "print(noneC, len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(dataset,batch_size = 1, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cuda\n"
     ]
    }
   ],
   "source": [
    "model = InputInjection()\n",
    "model.load_state_dict(torch.load(f'inputinjection-train-1.weights'))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'running on {device}')\n",
    "model.to(device)\n",
    "writer = SummaryWriter()\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params,lr=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [   0/2197]  eta: 0:00:04    time: 0.0020  data: 0.0020  max mem: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [ 100/2197]  eta: 0:02:27  model_time: 0.1486 (0.1701)  evaluator_time: 0.0010 (0.0012)  time: 0.0685  data: 0.0006  max mem: 539\n",
      "Test:  [ 200/2197]  eta: 0:02:14  model_time: 0.1496 (0.1595)  evaluator_time: 0.0010 (0.0013)  time: 0.0537  data: 0.0005  max mem: 539\n",
      "Test:  [ 300/2197]  eta: 0:02:10  model_time: 0.1496 (0.1559)  evaluator_time: 0.0010 (0.0013)  time: 0.0691  data: 0.0007  max mem: 539\n",
      "Test:  [ 400/2197]  eta: 0:02:04  model_time: 0.1496 (0.1542)  evaluator_time: 0.0010 (0.0013)  time: 0.0763  data: 0.0006  max mem: 539\n",
      "Test:  [ 500/2197]  eta: 0:02:00  model_time: 0.1496 (0.1533)  evaluator_time: 0.0010 (0.0013)  time: 0.0766  data: 0.0006  max mem: 539\n",
      "Test:  [ 600/2197]  eta: 0:01:49  model_time: 0.1486 (0.1527)  evaluator_time: 0.0010 (0.0013)  time: 0.0531  data: 0.0006  max mem: 539\n",
      "Test:  [ 700/2197]  eta: 0:01:39  model_time: 0.1486 (0.1523)  evaluator_time: 0.0010 (0.0013)  time: 0.0537  data: 0.0007  max mem: 539\n",
      "Test:  [ 800/2197]  eta: 0:01:32  model_time: 0.1496 (0.1519)  evaluator_time: 0.0010 (0.0013)  time: 0.0685  data: 0.0006  max mem: 539\n",
      "Test:  [ 900/2197]  eta: 0:01:24  model_time: 0.1486 (0.1517)  evaluator_time: 0.0010 (0.0013)  time: 0.0686  data: 0.0006  max mem: 539\n",
      "Test:  [1000/2197]  eta: 0:01:17  model_time: 0.1496 (0.1514)  evaluator_time: 0.0010 (0.0013)  time: 0.0611  data: 0.0007  max mem: 539\n",
      "Test:  [1100/2197]  eta: 0:01:11  model_time: 0.1496 (0.1512)  evaluator_time: 0.0010 (0.0013)  time: 0.0688  data: 0.0007  max mem: 539\n",
      "Test:  [1200/2197]  eta: 0:01:05  model_time: 0.1486 (0.1511)  evaluator_time: 0.0010 (0.0013)  time: 0.0683  data: 0.0006  max mem: 539\n",
      "Test:  [1300/2197]  eta: 0:00:59  model_time: 0.1496 (0.1510)  evaluator_time: 0.0010 (0.0013)  time: 0.0536  data: 0.0007  max mem: 539\n",
      "Test:  [1400/2197]  eta: 0:00:53  model_time: 0.1496 (0.1509)  evaluator_time: 0.0010 (0.0012)  time: 0.0686  data: 0.0007  max mem: 539\n",
      "Test:  [1500/2197]  eta: 0:00:46  model_time: 0.1496 (0.1508)  evaluator_time: 0.0010 (0.0012)  time: 0.0610  data: 0.0008  max mem: 539\n",
      "Test:  [1600/2197]  eta: 0:00:40  model_time: 0.1496 (0.1508)  evaluator_time: 0.0010 (0.0012)  time: 0.0686  data: 0.0006  max mem: 539\n",
      "Test:  [1700/2197]  eta: 0:00:33  model_time: 0.1496 (0.1508)  evaluator_time: 0.0010 (0.0012)  time: 0.0991  data: 0.0007  max mem: 539\n",
      "Test:  [1800/2197]  eta: 0:00:26  model_time: 0.1496 (0.1507)  evaluator_time: 0.0010 (0.0012)  time: 0.0840  data: 0.0007  max mem: 539\n",
      "Test:  [1900/2197]  eta: 0:00:20  model_time: 0.1496 (0.1507)  evaluator_time: 0.0010 (0.0012)  time: 0.0913  data: 0.0008  max mem: 539\n",
      "Test:  [2000/2197]  eta: 0:00:13  model_time: 0.1496 (0.1507)  evaluator_time: 0.0010 (0.0012)  time: 0.0685  data: 0.0007  max mem: 539\n",
      "Test:  [2100/2197]  eta: 0:00:06  model_time: 0.1496 (0.1506)  evaluator_time: 0.0010 (0.0012)  time: 0.0764  data: 0.0007  max mem: 539\n",
      "Test:  [2196/2197]  eta: 0:00:00  model_time: 0.1496 (0.1506)  evaluator_time: 0.0010 (0.0012)  time: 0.0613  data: 0.0008  max mem: 539\n",
      "Test: Total time: 0:02:28 (0.0676 s / it)\n",
      "Averaged stats: model_time: 0.1496 (0.1506)  evaluator_time: 0.0010 (0.0012)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.700\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tools.coco_eval.CocoEvaluator at 0x22bff1fa310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(writer, model, train, device, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[  9.2440,   2.7264,  89.3597,  95.1486],\n",
      "        [105.4982,  89.5808, 127.3933,  95.7915],\n",
      "        [105.4621,  80.5789, 125.7354,  95.7275],\n",
      "        [ 68.4715,   5.6651, 122.3567,  94.8436]], device='cuda:0',\n",
      "       grad_fn=<StackBackward>), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.9972, 0.3009, 0.1932, 0.0569], device='cuda:0',\n",
      "       grad_fn=<IndexBackward>)}]\n",
      "({'boxes': tensor([[10.,  1., 93., 95.]]), 'labels': tensor([1]), 'image_id': tensor(617), 'area': tensor(617)},)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for img, spectr, lab in train:\n",
    "    if img is None:\n",
    "        continue\n",
    "    if img[0] is None:\n",
    "        continue\n",
    "    img = torch.unsqueeze(img[0], 0).float().to(device)\n",
    "    spectr = torch.unsqueeze(spectr[0], 0).float().to(device)\n",
    "    output = model(img, spectr)\n",
    "    print(output)\n",
    "    print(lab)\n",
    "    break\n",
    "# it's probably not training because the gradient isn't flowing back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(writer, model, optimizer, train, device, epoch, print_freq=100)\n",
    "    evaluate(writer, model, train, device, print_freq=100)\n",
    "    torch.save(model.state_dict(), f'inputinjection-train-2.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
